\begin{longtable}{|l|l|l|l|l|>{\columncolor{worstColumnColor}}l|}
\hline
\textbf{parameter name} & \multicolumn{5}{c|}{\textbf{worst values}} \\
\hline
\textit{test accuracy}   & 0.08544 & 0.08516 &  0.0845 &  0.0836 &  0.0821 \\
final validation accuracy & 0.08655 & 0.0833  & 0.085333 & 0.086567 & 0.0852  \\
training time            & 1.2915  & 1.3563  & 1.4319  & 5.6985  & 6.3722  \\
neurons per layer        & (20, 15, 10) & (50, 10) & (32,)   & (32,)   & (20, 15, 10) \\
{\color{equalParamColor} activation functions } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } \\
last activation function & sigmoid & sigmoid & softmax & sigmoid & sigmoid \\
loss function            & cat-cross & MSE     & MSE     & MSE     & MSE     \\
{\color{equalParamColor} training data percentage } & {\color{equalParamColor} 1 } & {\color{equalParamColor} 1 } & {\color{equalParamColor} 1 } & {\color{equalParamColor} 1 } & {\color{equalParamColor} 1 } \\
number of epochs         & 5       & 5       & 5       & 50      & 5       \\
batch size               & 10000   & 10000   & 1000    & 10000   & 100     \\
optimizer                & Adam    & cAdam   & Adam    & Adam    & Adam    \\
{\color{equalParamColor} learning rate } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } \\
{\color{equalParamColor} $\varepsilon$ } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } \\
\hline

\caption{worst settings regarding \textit{test accuracy} for the MNIST dataset}
\label{table:test_accuracy_worst_mnist}
\end{longtable}
